#####################################################################
# GPU KERNELS FOR 2D
#####################################################################
# CELL LIST
#####################################################################
"""
    cellmap_2d!(pcell, cellpnum, points,  h, offset)  

Map each point to cell and count number of points in each cell.

For each coordinates cell number calculated:

```julia
csáµ¢ = size(cellpnum, 1) 
pâ‚  =  (xâ‚ - offsetâ‚) * hâ‚â»Â¹
páµ¢â‚ = ceil(min(max(pâ‚, 1), csáµ¢))
```

"""
function cellmap_2d!(pcell, cellpnum, points,  h, offset)  
    hâ»Â¹ = (1/h[1], 1/h[2])
    kernel = @cuda launch=false kernel_cellmap_2d!(pcell, cellpnum, points,  hâ»Â¹, offset) 
    config = launch_configuration(kernel.fun)
    threads = min(size(points, 1), config.threads)
    blocks = cld(size(points, 1), threads)
    CUDA.@sync kernel(pcell, cellpnum, points,  hâ»Â¹, offset; threads = threads, blocks = blocks)
end
function kernel_cellmap_2d!(pcell, cellpnum, points,  hâ»Â¹, offset) 
    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x
    csáµ¢ = size(cellpnum, 1) 
    csâ±¼ = size(cellpnum, 2) 
    if i <= length(points)
        @fastmath  pâ‚ =  (points[i][1] - offset[1]) * hâ»Â¹[1]
        @fastmath  pâ‚‚ =  (points[i][2] - offset[2]) * hâ»Â¹[2]
        páµ¢â‚ = ceil(Int32, min(max(pâ‚, 1), csáµ¢)) 
        páµ¢â‚‚ = ceil(Int32, min(max(pâ‚‚, 1), csâ±¼))
        # maybe add check:  is particle in simulation range? and include only if in simulation area
        pcell[i] = (páµ¢â‚, páµ¢â‚‚)

        CUDA.@atomic cellpnum[páµ¢â‚, páµ¢â‚‚] += one(Int32) 
    end
    return nothing
end
#####################################################################
"""
    fillcells_naive_2d!(celllist, cellpnum, pcell) 
    
Fill cell list with cell. Naive approach. No bound check. Values in `pcell` list shoid be in range of `cellpnum` and `celllist`.
"""
function fillcells_naive_2d!(celllist, cellpnum, pcell)  
    CLn, CLx, CLy = size(celllist)
    if size(cellpnum) != (CLx, CLy) error("cell list dimension $((CLx, CLy)) not equal cellpnum $(size(cellpnum))...") end
    gpukernel = @cuda launch=false kernel_fillcells_naive_2d!(celllist, cellpnum, pcell) 
    config = launch_configuration(gpukernel.fun)
    threads = min(length(pcell), config.threads)
    blocks = cld(length(pcell), threads)
    CUDA.@sync gpukernel(celllist, cellpnum, pcell; threads = threads, blocks = blocks)
end
function kernel_fillcells_naive_2d!(celllist, cellpnum, pcell) 
    indexáµ¢ = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if indexáµ¢ <= length(pcell)
        # no bound check - all should be done before
        páµ¢, pâ±¼ = pcell[indexáµ¢]
        n = CUDA.@atomic cellpnum[páµ¢, pâ±¼] += 1
        celllist[n + 1, páµ¢, pâ±¼] = indexáµ¢
    end
    return nothing
end
#####################################################################
#####################################################################
"""
    Ğ¼axpairs_2d(cellpnum)

Maximum number of pairs.
"""
function Ğ¼axpairs_2d(cellpnum)
    cnt        = CUDA.zeros(Int, 1)
    Nx, Ny     = size(cellpnum)
    gpukernel  = @cuda launch=false kernel_Ğ¼axpairs_2d!(cellpnum, cnt)
    config     = launch_configuration(gpukernel.fun)
    maxThreads = config.threads
    Tx         = min(maxThreads, Nx)
    Ty         = min(fld(maxThreads, Tx), Ny)
    Bx, By     = cld(Nx, Tx), cld(Ny, Ty) 
    threads    = (Tx, Ty)
    blocks     = (Bx, By)
    CUDA.@sync gpukernel(cellpnum, cnt; threads = threads, blocks = blocks)
    CUDA.@allowscalar cnt[1]
end
function kernel_Ğ¼axpairs_2d!(cellpnum, cnt)
    indexáµ¢ = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    indexâ±¼ = (blockIdx().y - Int32(1)) * blockDim().y + threadIdx().y 
    Nx, Ny = size(cellpnum)
    if  indexáµ¢ <= Nx && indexâ±¼ <= Ny 
        n = cellpnum[indexáµ¢, indexâ±¼] 
        if n > 0
            m         = 0
            neibcelláµ¢ = indexáµ¢ - 1
            neibcellâ±¼ = indexâ±¼ + 1
            if  0 < neibcelláµ¢ <= Nx && 0 < neibcellâ±¼ <= Ny 
                m += cellpnum[neibcelláµ¢, neibcellâ±¼] 
            end
            neibcelláµ¢ = indexáµ¢ 
            neibcellâ±¼ = indexâ±¼ + 1
            if 0 < neibcelláµ¢ <= Nx && 0 < neibcellâ±¼ <= Ny 
                m += cellpnum[neibcelláµ¢, neibcellâ±¼] 
            end
            neibcelláµ¢ = indexáµ¢ + 1
            neibcellâ±¼ = indexâ±¼ + 1
            if 0 < neibcelláµ¢ <= Nx && 0 < neibcellâ±¼ <= Ny 
                m += cellpnum[neibcelláµ¢, neibcellâ±¼] 
            end
            neibcelláµ¢ = indexáµ¢ + 1
            neibcellâ±¼ = indexâ±¼ 
            if 0 < neibcelláµ¢ <= Nx && 0 < neibcellâ±¼ <= Ny 
                m += cellpnum[neibcelláµ¢, neibcellâ±¼] 
            end
            val  = Int((n * (n - 1)) * 0.5) + m * n
            CUDA.@atomic cnt[1] += val
        end
    end
    return nothing
end
#####################################################################
"""
    neib_internal_2d!(pairs, cnt, cellpnum, points, celllist, dist)

Find all pairs with distance < h in one cell.
"""
function neib_internal_2d!(pairs, cnt, cellpnum, points, celllist, dist)
    distÂ² = dist^2
    CLn, CLx, CLy = size(celllist)
    Nx, Ny = size(cellpnum)
    if (Nx, Ny) != (CLx, CLy) error("cell list dimension ($((CLx, CLy))) not equal cellpnum $(size(cellpnum))...") end
    gpukernel = @cuda launch=false kernel_neib_internal_2d!(pairs, cnt, cellpnum, points, celllist, distÂ², 6)
    config = launch_configuration(gpukernel.fun)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Ty  = min(fld(maxThreads, Tx), Ny)
    Bx, By = cld(Nx, Tx), cld(Ny, Ty)  # Blocks in grid.
    threads = (Tx, Ty)
    blocks  = Bx, By
    cs = fld(attribute(device(), CUDA.DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN),  Tx * Ty * sizeof(Tuple{Int32, Int32}))
    CUDA.@sync gpukernel(pairs, cnt, cellpnum, points, celllist, distÂ², cs; threads = threads, blocks = blocks, shmem= Tx * Ty * cs * sizeof(Tuple{Int32, Int32}))
end
function kernel_neib_internal_2d!(pairs, cnt, cellpnum, points, celllist, distÂ², cs)  # cs - cache length for each thread
    threadx = threadIdx().x
    thready = threadIdx().y
    indexáµ¢ = (blockIdx().x - Int32(1)) * blockDim().x + threadx
    indexâ±¼ = (blockIdx().y - Int32(1)) * blockDim().y + thready
    #indexâ‚– = (blockIdx().z - Int32(1)) * blockDim().z + threadIdx().z 
    Nx, Ny = size(cellpnum)
    cache  = CuDynamicSharedArray(Tuple{Int32, Int32}, (cs, blockDim().x , blockDim().y))
    if indexáµ¢ <= Nx && indexâ±¼ <= Ny && cellpnum[indexáµ¢, indexâ±¼] > 1
        ccnt  = zero(Int32)
        len = cellpnum[indexáµ¢, indexâ±¼]
        for i = 1:len - 1
            indi = celllist[i, indexáµ¢, indexâ±¼]
            páµ¢  = points[indi]
            for j = i + 1:len
                indj = celllist[j, indexáµ¢, indexâ±¼]
                pâ±¼   = points[indj]
                distance = (páµ¢[1] - pâ±¼[1])^2 + (páµ¢[2] - pâ±¼[2])^2 # calculate rÂ² to awoid sqrt, compare with squared maximum distance distÂ²
                if distance < distÂ²
                    #n = CUDA.@atomic cnt[1] += 1
                    #pairs[n+1] = minmax(indi, indj)
                    ccnt += 1
                    cache[ccnt, threadx, thready] = minmax(indi, indj)
                    if ccnt == cs
                        s  = CUDA.@atomic cnt[1] += ccnt
                        if s + ccnt <=length(pairs)
                            for cind in 1:ccnt
                                pairs[s + cind] = cache[cind, threadx, thready]
                            end
                        end
                        ccnt = 0
                    end
                end
            end
        end
        if ccnt > 0 
            s  = CUDA.@atomic cnt[1] += ccnt
            if s + ccnt <=length(pairs)
                for cind in 1:ccnt
                    pairs[s + cind] = cache[cind, threadx, thready]
                end
            end
        end
    end
    return nothing
end
#####################################################################
"""
    neib_external_2d!(pairs, cnt, cellpnum, points, celllist, offset, dist)

Find all pairs with another cell shifted on offset.
"""
function neib_external_2d!(pairs, cnt, cellpnum, points, celllist, offset, dist)
    distÂ² = dist^2
    CLn, CLx, CLy = size(celllist)
    Nx, Ny = size(cellpnum)
    if (Nx, Ny) != (CLx, CLy) error("cell list dimension $((CLx, CLy)) not equal cellpnum $(size(cellpnum))...") end
    gpukernel = @cuda launch=false kernel_neib_external_2d!(pairs, cnt, cellpnum, points, celllist,  offset, distÂ², 6)
    config = launch_configuration(gpukernel.fun)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx) 
    Ty  = min(fld(maxThreads, Tx), Ny)
    Bx, By = cld(Nx, Tx), cld(Ny, Ty)  # Blocks in grid.
    threads = (Tx, Ty)
    blocks  = Bx, By
    cs = fld(attribute(device(), CUDA.DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN),  Tx * Ty * sizeof(Tuple{Int32, Int32}))
    CUDA.@sync gpukernel(pairs, cnt, cellpnum, points, celllist, offset, distÂ², cs; threads = threads, blocks = blocks, shmem= Tx * Ty * cs * sizeof(Tuple{Int32, Int32}))
end
function kernel_neib_external_2d!(pairs, cnt, cellpnum, points, celllist,  offset, distÂ², cs)
    threadx = threadIdx().x
    thready = threadIdx().y
    indexáµ¢ = (blockIdx().x - Int32(1)) * blockDim().x + threadx
    indexâ±¼ = (blockIdx().y - Int32(1)) * blockDim().y + thready
    cache  = CuDynamicSharedArray(Tuple{Int32, Int32}, (cs, blockDim().x , blockDim().y))
    Nx, Ny = size(cellpnum)
    neibcelláµ¢ = indexáµ¢ + offset[1]
    neibcellâ±¼ = indexâ±¼ + offset[2]
    if 0 < neibcelláµ¢ <= Nx &&  0 < neibcellâ±¼ <= Ny && indexáµ¢ <= Nx && indexâ±¼ <= Ny && cellpnum[indexáµ¢, indexâ±¼] > 0 #&& cellpnum[neibcelláµ¢, neibcellâ±¼] > 0
        ccnt  = zero(Int32)
        iinds = view(celllist, 1:cellpnum[indexáµ¢, indexâ±¼], indexáµ¢, indexâ±¼)
        jinds = view(celllist, 1:cellpnum[neibcelláµ¢, neibcellâ±¼], neibcelláµ¢, neibcellâ±¼)
        for i in iinds
            páµ¢ = points[i]
            for j in jinds
                pâ±¼ = points[j]
                distance = (páµ¢[1] - pâ±¼[1])^2 + (páµ¢[2] - pâ±¼[2])^2
                if distance < distÂ²
                    #n = CUDA.@atomic cnt[1] += 1
                    #pairs[n + 1] = minmax(i, j)
                    
                    ccnt += 1
                    cache[ccnt, threadx, thready] = minmax(i, j)
                    if ccnt == cs
                        s  = CUDA.@atomic cnt[1] += ccnt
                        if s + ccnt <=length(pairs)
                            for cind in 1:ccnt
                                pairs[s + cind] = cache[cind, threadx, thready]
                            end
                        end
                        ccnt = 0
                    end 

                end
            end  
        end   
        if ccnt > 0 
            s  = CUDA.@atomic cnt[1] += ccnt
            if s + ccnt <=length(pairs)
                for cind in 1:ccnt
                    pairs[s + cind] = cache[cind, threadx, thready]
                end
            end
        end
        
    end
    return nothing
end

#####################################################################
# 
#####################################################################
function pranges!(ranges, pairs) 
    gpukernel = @cuda launch=false kernel_pranges!(ranges, pairs) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(ranges)
    maxThreads = config.threads
    Tx  = min(32, maxThreads, Nx)
    CUDA.@sync gpukernel(ranges, pairs; threads = Tx, blocks = 1, shmem = Tx * sizeof(Int))
end
function kernel_pranges!(ranges, pairs) 
    index  = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    thread = threadIdx().x
    stride = gridDim().x * blockDim().x
    tn     = blockDim().x
    cache  = CuDynamicSharedArray(Int, tn)
    cache[thread] = 1
    rs = 0
    re = 0
    sync_threads()
    while index <= length(ranges)
        s = false
        rs = 0
        re = 0
        for i = cache[thread]:length(pairs)
            fpi = first(pairs[i])
            if fpi == index && !s
                s  = true
                rs = i
            elseif fpi != index && s
                re = i - 1
                ranges[index] = (rs, re)
                cache[thread] = i
                break
            #elseif (!s && index < fpi) || fpi == 0
            #    ranges[index] = (0, 0)
            #    break
            end
        end
        if s  == true && re == 0 
            ranges[index] = (rs, length(pairs))
        end
        sync_threads()
        if thread == 1
            maxindex = 1
            for i = 1:tn
                if cache[i] > maxindex maxindex = cache[i] end
            end
            for i = 1:tn
                cache[i] = maxindex
            end
        end
        index += stride
        sync_threads()
    end
    return nothing
end

#âˆ‘âˆ‚vâˆ‚t, âˆ‘âˆ‚Ïâˆ‚t, pairs, W, âˆ‡W, âˆ‘W, âˆ‘âˆ‡W, Ï, P, v, points, dx, h, hâ»Â¹, H, Hâ»Â¹, Î·Â², mâ‚€, Ïâ‚€, câ‚€, Î³, Î³â»Â¹,g, Î´áµ©, Î±, Î², ğœˆ, s, dpc_lâ‚€, dpc_pmin, dpc_pmax, dpc_Î», xsph_ğœ€, Î”t, sphkernel, ptype
#####################################################################
#####################################################################
# SPH
#####################################################################
"""

    W_2d!(W, pairs, sphkernel, Hâ»Â¹) 

Compute kernel values for each particles pair in list. Update `W`. See SPHKernels.jl for details.
"""
function W_2d!(W, pairs, points, Hâ»Â¹, sphkernel) 
    gpukernel = @cuda launch=false kernel_W_2d!(W, pairs, points, Hâ»Â¹, sphkernel) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(W, pairs, points, Hâ»Â¹, sphkernel; threads = Tx, blocks = Bx)
end
function kernel_W_2d!(W, pairs, points, Hâ»Â¹, sphkernel) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            xáµ¢       = points[páµ¢]
            xâ±¼       = points[pâ±¼]
            Î”x       = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            d        = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            u        = d * Hâ»Â¹
            w        = ğ’²(sphkernel, u, Hâ»Â¹)
            W[index] = w
        end
    end
    return nothing
end
#####################################################################
#
#####################################################################
"""

    âˆ‘W_2d!(âˆ‘W, pairs, sphkernel, Hâ»Â¹) 

Compute sum of kernel values for each particles pair in list. Add to `âˆ‘W`. See SPHKernels.jl for details.
"""
function âˆ‘W_2d!(âˆ‘W, pairs, points, sphkernel, Hâ»Â¹) 
    gpukernel = @cuda launch=false kernel_âˆ‘W_2d!(âˆ‘W, pairs, points, sphkernel, Hâ»Â¹) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘W, pairs, points, sphkernel, Hâ»Â¹; threads = Tx, blocks = Bx)
end
function kernel_âˆ‘W_2d!(âˆ‘W, pairs, points, sphkernel, Hâ»Â¹) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            d     = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            u     = d * Hâ»Â¹
            w     = ğ’²(sphkernel, u, Hâ»Â¹)
            CUDA.@atomic âˆ‘W[páµ¢] += w
            CUDA.@atomic âˆ‘W[pâ±¼] += w
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‡W_2d!(âˆ‡W, pairs, points, kernel, Hâ»Â¹) 

Compute gradients. Update `âˆ‡W`. See SPHKernels.jl for details.

"""
function âˆ‡W_2d!(âˆ‡W, pairs, points, Hâ»Â¹, kernel) 
    gpukernel = @cuda launch=false kernel_âˆ‡W_2d!(âˆ‡W, pairs, points, Hâ»Â¹, kernel) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‡W, pairs, points, Hâ»Â¹, kernel; threads = Tx, blocks = Bx)
end
function kernel_âˆ‡W_2d!(âˆ‡W, pairs, points, Hâ»Â¹, kernel) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            xáµ¢        = points[páµ¢]
            xâ±¼        = points[pâ±¼]
            Î”x        = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            r         = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            u         = r * Hâ»Â¹
            dwk_r     = dğ’²(kernel, u, Hâ»Â¹) / r
            âˆ‡W[index] = (Î”x[1] * dwk_r, Î”x[2] * dwk_r)
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, âˆ‡W, pairs, points, kernel, Hâ»Â¹) 

Compute gradients. Add sum to `âˆ‘âˆ‡W` and update `âˆ‡W`. See SPHKernels.jl for details.

"""
function âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    gpukernel = @cuda launch=false kernel_âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‡W, âˆ‡W, pairs, points, kernel, Hâ»Â¹; threads = Tx, blocks = Bx)
end
function kernel_âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            r     = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            u     = r * Hâ»Â¹
            dwk_r = dğ’²(kernel, u, Hâ»Â¹) / r
            âˆ‡w    = (Î”x[1] * dwk_r, Î”x[2] * dwk_r)
            if isnan(dwk_r) 
                @cuprintln "kernel W_2d  dwk_r = $dwk_r, pair = $pair"
                error() 
            end
            âˆ‘âˆ‡WË£ = âˆ‘âˆ‡W[1]
            âˆ‘âˆ‡WÊ¸ = âˆ‘âˆ‡W[2]
            CUDA.@atomic âˆ‘âˆ‡WË£[páµ¢] += âˆ‡w[1]
            CUDA.@atomic âˆ‘âˆ‡WÊ¸[páµ¢] += âˆ‡w[2]
            CUDA.@atomic âˆ‘âˆ‡WË£[pâ±¼] -= âˆ‡w[1]
            CUDA.@atomic âˆ‘âˆ‡WÊ¸[pâ±¼] -= âˆ‡w[2]
            âˆ‡W[index] = âˆ‡w
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, pairs, points, kernel, Hâ»Â¹) 

Compute gradients. Add sum to âˆ‘âˆ‡W. See SPHKernels.jl for details.

"""
function âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    gpukernel = @cuda launch=false kernel_âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‡W, pairs, points, kernel, Hâ»Â¹; threads = Tx, blocks = Bx)
end
function kernel_âˆ‘âˆ‡W_2d!(âˆ‘âˆ‡W, pairs, points, kernel, Hâ»Â¹) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            r     = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            u     = r * Hâ»Â¹
            dwk_r = dğ’²(kernel, u, Hâ»Â¹) / r
            âˆ‡w    = (Î”x[1] * dwk_r, Î”x[2] * dwk_r)
            âˆ‘âˆ‡WË£ = âˆ‘âˆ‡W[1]
            âˆ‘âˆ‡WÊ¸ = âˆ‘âˆ‡W[2]
            CUDA.@atomic âˆ‘âˆ‡WË£[páµ¢] += âˆ‡w[1]
            CUDA.@atomic âˆ‘âˆ‡WÊ¸[páµ¢] += âˆ‡w[2]

            CUDA.@atomic âˆ‘âˆ‡WË£[pâ±¼] -= âˆ‡w[1]
            CUDA.@atomic âˆ‘âˆ‡WÊ¸[pâ±¼] -= âˆ‡w[2]
        end
    end
    return nothing
end

#âˆ‘âˆ‚vâˆ‚t, âˆ‘âˆ‚Ïâˆ‚t, pairs, W, âˆ‡W, âˆ‘W, âˆ‘âˆ‡W, Ï, P, v, points, dx, h, hâ»Â¹, H, Hâ»Â¹, Î·Â², mâ‚€, Ïâ‚€, câ‚€, Î³, Î³â»Â¹, g, Î´áµ©, Î±, Î², ğœˆ, s, dpc_lâ‚€, dpc_pmin, dpc_pmax, dpc_Î», xsph_ğœ€, Î”t, sphkernel, ptype
#####################################################################
# https://discourse.julialang.org/t/can-this-be-written-even-faster-cpu/109924/28
@inline function powfancy7th(x, Î³â»Â¹, Î³)
    if Î³ == 7
        # todo tune the magic constant
        # initial guess based on fast inverse sqrt trick but adjusted to compute x^(1/7)
        t = copysign(reinterpret(Float64, 0x36cd000000000000 + reinterpret(UInt64,abs(x))Ã·7), x)
        @fastmath for _ in 1:2
        # newton's method for t^3 - x/t^4 = 0
            t2 = t*t
            t3 = t2*t
            t4 = t2*t2
            xot4 = x/t4
            t = t - t*(t3 - xot4)/(4*t3 + 3*xot4)
        end
        return t
    end
    return x^Î³â»Â¹
end
"""
    
    âˆ‚Ïâˆ‚tDDT!(âˆ‘âˆ‚Ïâˆ‚t,  âˆ‡W, pairs, points, h, mâ‚€, Î´áµ©, câ‚€, Î³, g, Ïâ‚€, Ï, v, ptype) 

Compute âˆ‚Ïâˆ‚t - density derivative includind density diffusion. *Replace all values and update `âˆ‘âˆ‚Ïâˆ‚t`.*

```math

\\frac{\\partial \\rho_i}{\\partial t} = \\sum  m_j \\textbf{v}_{ij} \\cdot \\nabla_i W_{ij} + \\delta_{\\Phi} h c_0 \\sum \\Psi_{ij} \\cdot \\nabla_i W_{ij} \\frac{m_j}{\\rho_j}

\\\\

\\Psi_{ij} = 2 (\\rho_{ij}^T - \\rho_{ij}^H) \\frac{\\textbf{r}_{ij}}{r_{ij}^2 + \\eta^2}

\\\\

\\rho_{ij}^H = \\rho_0 \\left( \\sqrt[\\gamma]{\\frac{P_{ij}^H + 1}{C_b}} - 1\\right)

\\\\

P_{ij}^H = \\rho_0 g z_{ij}

```

``z_{ij}`` - vertical distance.

"""
function âˆ‚Ïâˆ‚tDDT!(âˆ‘âˆ‚Ïâˆ‚t::CuArray{T}, pairs, âˆ‡W, Ï, v, points, h, mâ‚€, Ïâ‚€, câ‚€, Î³, g, Î´áµ©, ptype; minthreads::Int = 1024)  where T
    fill!(âˆ‘âˆ‚Ïâˆ‚t, zero(T))
    Î·Â²    = (0.1*h)*(0.1*h)
    Î³â»Â¹   = 1/Î³
    DDTkh = 2 * h * Î´áµ© * câ‚€
    Cb    = (câ‚€ * câ‚€ * Ïâ‚€) * Î³â»Â¹
    DDTgz = Ïâ‚€ * g / Cb
    if length(pairs) != length(âˆ‡W) error("Length shoul be equal") end

    gpukernel = @cuda launch=false kernel_âˆ‚Ïâˆ‚tDDT!(âˆ‘âˆ‚Ïâˆ‚t, pairs, âˆ‡W, Ï, v, points, Î·Â², mâ‚€, Ïâ‚€, Î³, Î³â»Â¹, DDTkh, DDTgz, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(minthreads, maxThreads, Nx)
    Bx  = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚Ïâˆ‚t, pairs, âˆ‡W, Ï, v, points, Î·Â², mâ‚€, Ïâ‚€, Î³, Î³â»Â¹, DDTkh, DDTgz, ptype; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚Ïâˆ‚tDDT!(âˆ‘âˆ‚Ïâˆ‚t, pairs, âˆ‡W, Ï, v, points, Î·Â², mâ‚€, Ïâ‚€, Î³, Î³â»Â¹, DDTkh, DDTgz, ptype) 
    tindex = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    stride = gridDim().x * blockDim().x
    index      = tindex
    # move it outside kernel
    #Î³â»Â¹  = 1/Î³
    #Î·Â²   = (0.1*h)*(0.1*h)
    
    #DDTkh = 2 * h * Î´áµ© * câ‚€

    while index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ > 0 && ptype[páµ¢] > 0 && ptype[pâ±¼] > 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            rÂ²    = Î”x[1]^2 + Î”x[2]^2 
            # for timestep Î”tÂ½ d != actual range
            # one way - not calculate values out of 2h
            # if rÂ² > (2h)^2 return nothing end
            #=
            Cb = (câ‚€ * câ‚€ * Ïâ‚€) * Î³â»Â¹
            Pá´´ =  Ïâ‚€ * g * z
            áµ¸áµ€á´´
            =#
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]

            Î”v    = (v[páµ¢][1] - v[pâ±¼][1], v[páµ¢][2] - v[pâ±¼][2])

            âˆ‡Wáµ¢â±¼  = âˆ‡W[index]
            #=
            z  = Î”x[2]
            Cb = (câ‚€ * câ‚€ * Ïâ‚€) * Î³â»Â¹
            Pá´´ =  Ïâ‚€ * g * z
            Ïá´´ =  Ïâ‚€ * (((Pá´´ + 1)/Cb)^Î³â»Â¹ - 1)
            Ïˆ  = 2 * (Ïáµ¢ - Ïâ±¼) * Î”x / rÂ²
            =#
            dot3  = -(Î”x[1] * âˆ‡Wáµ¢â±¼[1] + Î”x[2] * âˆ‡Wáµ¢â±¼[2]) #  - Î”x â‹… âˆ‡Wáµ¢â±¼

            # as actual range at timestep Î”tÂ½  may be greateg  - some problems can be here
            # if 1 + DDTgz * Î”x[2] < 0 || 1 - DDTgz * Î”x[2] < 0 return nothing end
            
            mâ‚€dot     = mâ‚€ * (Î”v[1] * âˆ‡Wáµ¢â±¼[1] + Î”v[2] * âˆ‡Wáµ¢â±¼[2])  #  Î”v â‹… âˆ‡Wáµ¢â±¼
            âˆ‘âˆ‚Ïâˆ‚ti = âˆ‘âˆ‚Ïâˆ‚tj = mâ‚€dot

            if ptype[páµ¢] >= 1
                drhopvp = Ïâ‚€ * powfancy7th(1 + DDTgz * Î”x[2], Î³â»Â¹, Î³) - Ïâ‚€ 
                #drhopvp = Ïâ‚€ * (1 + DDTgz * Î”x[2])^Î³â»Â¹ - Ïâ‚€
                visc_densi = DDTkh  * (Ïâ±¼ - Ïáµ¢ - drhopvp) / (rÂ² + Î·Â²)
                delta_i    = visc_densi * dot3 * mâ‚€ / Ïâ±¼
                âˆ‘âˆ‚Ïâˆ‚ti    += delta_i #* (ptype[páµ¢] >= 1)
            end
            CUDA.@atomic âˆ‘âˆ‚Ïâˆ‚t[páµ¢] += âˆ‘âˆ‚Ïâˆ‚ti 

            if ptype[pâ±¼] >= 1
                drhopvn = Ïâ‚€ * powfancy7th(1 - DDTgz * Î”x[2], Î³â»Â¹, Î³) - Ïâ‚€
                #drhopvn = Ïâ‚€ * (1 - DDTgz * Î”x[2])^Î³â»Â¹ - Ïâ‚€
                visc_densi = DDTkh  * (Ïáµ¢ - Ïâ±¼ - drhopvn) / (rÂ² + Î·Â²)
                delta_j    = visc_densi * dot3 * mâ‚€ / Ïáµ¢
                âˆ‘âˆ‚Ïâˆ‚tj    += delta_j #* (ptype[pâ±¼] >= 1)
            end
            CUDA.@atomic âˆ‘âˆ‚Ïâˆ‚t[pâ±¼] += âˆ‘âˆ‚Ïâˆ‚tj 
            
            #=
            if isnan(delta_j) || isnan(mâ‚€dot)  || isnan(Ïáµ¢) || isnan(Ïâ±¼) 
                @cuprintln "kernel_DDT 1 isnan dx1 = $(Î”x[1]) , dx2 = $(Î”x[2]) rhoi = $Ïáµ¢ , dot3 = $dot3 , visc_densi = $visc_densi drhopvn = $drhopvn $(âˆ‡W[1]) $(Î”v[1])"
                error() 
            end
            if isinf(delta_j) || isinf(mâ‚€dot)  || isinf(delta_i) 
                @cuprintln "kernel_DDT 2 inf: dx1 = $(Î”x[1]) , dx2 = $(Î”x[2]) rhoi = $Ïáµ¢ , rhoj = $Ïâ±¼ , dot3 = $dot3 ,  delta_i = $delta_i , delta_j = $delta_j , drhopvn = $drhopvn , visc_densi = $visc_densi , $(âˆ‡W[1]) , $(Î”v[1])"
                error() 
            end
            =#
            #mlfac = MotionLimiter[páµ¢] * MotionLimiter[pâ±¼]
            #=
            if isnan(âˆ‘âˆ‚Ïâˆ‚tval1) || isnan(âˆ‘âˆ‚Ïâˆ‚tval2) || abs(âˆ‘âˆ‚Ïâˆ‚tval1) >  10000000 || abs(âˆ‘âˆ‚Ïâˆ‚tval2) >  10000000
                @cuprintln "kernel DDT: drhodti = $âˆ‘âˆ‚Ïâˆ‚ti drhodtj = $âˆ‘âˆ‚Ïâˆ‚tj, dx1 = $(Î”x[1]), dx2 = $(Î”x[2]) rhoi = $Ïáµ¢, rhoj = $Ïâ±¼, dot3 = $dot3, visc_densi = $visc_densi, drhopvn = $drhopvn, dw = $(âˆ‡W[1]),  dv = $(Î”v[1])"
                error() 
            end
            =#
            
        end
        index += stride
    end
    return nothing
end
#####################################################################
"""
    pressure(Ï, câ‚€, Î³, Ïâ‚€)

Equation of State in Weakly-Compressible SPH

```math
P = c_0^2 \\rho_0 * \\left[  \\left( \\frac{\\rho}{\\rho_0} \\right)^{\\gamma}  \\right]
```
"""
#=
function pressure(Ï, câ‚€, Î³, Ïâ‚€)
    return ((câ‚€ ^ 2 * Ïâ‚€) / Î³) * ((Ï / Ïâ‚€) ^ Î³ - 1)
end
function pressure(Ï, câ‚€, Î³, Ïâ‚€, Î³â»Â¹::Float64)
    return (câ‚€ ^ 2 * Ïâ‚€ * Î³â»Â¹) * ((Ï / Ïâ‚€) ^ Î³ - 1)
end
=#
# The correction is to be applied on boundary particles
# J. P. Hughes and D. I. Graham, â€œComparison of incompressible and weakly-compressible SPH models for free-surface water flowsâ€, Journal of Hydraulic Research, 48 (2010), pp. 105-117.
function pressure(Ï, Î³, Ïâ‚€, Pâ‚€, ptype)
    #return  Pâ‚€ * ((Ï / Ïâ‚€) ^ Î³ - 1) * (ptype < 1 && Ï < Ïâ‚€)
    if ptype < 0 && Ï < Ïâ‚€
        return 0.0
    end
    return  Pâ‚€ * ((Ï / Ïâ‚€) ^ Î³ - 1)
end

#####################################################################
"""
    
    pressure!(P, Ï, câ‚€, Î³, Ïâ‚€, ptype) 

Equation of State in Weakly-Compressible SPH.

```math
P = c_0^2 \\rho_0 * \\left[  \\left( \\frac{\\rho}{\\rho_0} \\right)^{\\gamma}  \\right]
```
"""
function pressure!(P, Ï, câ‚€, Î³, Ïâ‚€, ptype) 
    if length(P) != length(Ï) != length(ptype) error("Wrong length") end
    Pâ‚€  =  câ‚€ ^ 2 * Ïâ‚€ / Î³
    gpukernel = @cuda launch=false kernel_pressure!(P, Ï, Î³, Ïâ‚€, Pâ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(Ï)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(P, Ï, Î³, Ïâ‚€, Pâ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_pressure!(P, Ï, Î³, Ïâ‚€, Pâ‚€, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(Ï)
        P[index] = pressure(Ï[index], Î³, Ïâ‚€, Pâ‚€, ptype[index])
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‚vâˆ‚t!(âˆ‘âˆ‚vâˆ‚t,  âˆ‡W, pairs, mâ‚€, Ï, câ‚€, Î³, Ïâ‚€) 

The momentum equation (without dissipation and gravity). *Add to `âˆ‘âˆ‚vâˆ‚t`.*

```math
\\frac{\\partial \\textbf{v}_i}{\\partial t} = - \\sum  m_j \\left( \\frac{p_i}{\\rho^2_i} + \\frac{p_j}{\\rho^2_j} \\right) \\nabla_i W_{ij}
```

"""
function âˆ‚vâˆ‚t!(âˆ‘âˆ‚vâˆ‚t,  âˆ‡W, P, pairs, mâ‚€, Ï, ptype; minthreads::Int = 1024) 
    gpukernel = @cuda launch=false kernel_âˆ‚vâˆ‚t!(âˆ‘âˆ‚vâˆ‚t,  âˆ‡W, P, pairs, mâ‚€, Ï, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(minthreads, maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t,  âˆ‡W, P, pairs, mâ‚€, Ï, ptype; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚vâˆ‚t!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, P, pairs, mâ‚€, Ï, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] >= 0 && ptype[pâ±¼] >= 0
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]
            Páµ¢    = P[páµ¢]
            Pâ±¼    = P[pâ±¼]
            âˆ‡Wáµ¢â±¼  = âˆ‡W[index]
            Pfac  = (Páµ¢ + Pâ±¼) / (Ïáµ¢ * Ïâ±¼)
            âˆ‚vâˆ‚t  = (- mâ‚€ * Pfac * âˆ‡Wáµ¢â±¼[1], - mâ‚€ * Pfac * âˆ‡Wáµ¢â±¼[2])
            âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
            âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2]   
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[páµ¢] +=  âˆ‚vâˆ‚t[1]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[páµ¢] +=  âˆ‚vâˆ‚t[2]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[pâ±¼] -=  âˆ‚vâˆ‚t[1]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[pâ±¼] -=  âˆ‚vâˆ‚t[2]
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‚vâˆ‚t_av!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, pairs, points, h, Ï, Î±, v, câ‚€, mâ‚€)


Compute artificial viscosity part of âˆ‚vâˆ‚t. *Add to `âˆ‘âˆ‚vâˆ‚t`.*

```math
\\Pi_{ij} = \\begin{cases} \\frac{- \\alpha \\overline{c}_{ij} \\mu_{ij} + \\beta \\mu_{ij}^2 }{\\overline{\\rho}_{ij}} &  \\textbf{v}_{ij} \\cdot \\textbf{r}_{ij} < 0 \\\\ 0 &  otherwise \\end{cases}
```

```math
\\mu_{ij} = \\frac{h \\textbf{v}_{ij}\\cdot \\textbf{r}_{ij}}{r_{ij}^2 + \\eta^2}
```

```math
\\overline{c}_{ij}  = \\frac{c_i + c_j}{2}
```

```math
\\overline{\\rho}_{ij} = \\frac{\\rho_i + \\rho_j}{2}
```

```math
\\beta = 0

\\c_{ij} = c_0

\\m_i = m_j = m_0

```

Artificial viscosity part of momentum equation. 

```math
\\frac{\\partial \\textbf{v}_i}{\\partial t} = - \\sum  m_j \\Pi_{ij} \\nabla_i W_{ij}
```

J. Monaghan, Smoothed Particle Hydrodynamics, â€œAnnual Review of Astronomy and Astrophysicsâ€, 30 (1992), pp. 543-574.

"""
function âˆ‚vâˆ‚t_av!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, pairs, points, h, Ï, Î±, v, câ‚€, mâ‚€, ptype; minthreads::Int = 1024) 
    
    Î·Â²    = (0.1 * h) * (0.1 * h)
    gpukernel = @cuda launch=false kernel_âˆ‚vâˆ‚t_av!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, pairs, points, h, Î·Â², Ï, Î±, v, câ‚€, mâ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(minthreads, maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, pairs, points, h, Î·Â², Ï, Î±, v, câ‚€, mâ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚vâˆ‚t_av!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, pairs, points, h, Î·Â², Ï, Î±, v, câ‚€, mâ‚€, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x

    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] > 0 && ptype[pâ±¼] > 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            rÂ²    = Î”x[1]^2 + Î”x[2]^2 
            # for timestep Î”tÂ½ d != actual range
            # one way - not calculate values out of 2h
            # if rÂ² > (2h)^2 return nothing end
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]
            #=
            if isnan(Ïáµ¢) || iszero(Ïáµ¢) || Ïáµ¢ < 0.001 || isnan(Ïâ±¼) || iszero(Ïâ±¼) || Ïâ±¼ < 0.001
                @cuprintln "kernel Î : index =  $index, rhoi = $Ïáµ¢, rhoi = $Ïâ±¼, dx = $Î”x, r =  $rÂ², pair = $pair"
                error() 
            end
            =#
            Î”v    = (v[páµ¢][1] - v[pâ±¼][1], v[páµ¢][2] - v[pâ±¼][2])
            Ïâ‚˜     = (Ïáµ¢ + Ïâ±¼) * 0.5
            âˆ‡Wáµ¢â±¼   = âˆ‡W[index]
            cond   = Î”v[1] * Î”x[1] +  Î”v[2] * Î”x[2] 

            if cond < 0
                Î”Î¼   = h * cond / (rÂ² + Î·Â²)
                Î”Î    =  (-Î± * câ‚€ * Î”Î¼) / Ïâ‚˜
                Î”Î mâ‚€âˆ‡W = (-Î”Î  * mâ‚€ * âˆ‡Wáµ¢â±¼[1], -Î”Î  * mâ‚€ * âˆ‡Wáµ¢â±¼[2])
                #=
                if isnan(Î”Î mâ‚€âˆ‡W[1])
                    @cuprintln "kernel Î : Î  = $Î”Î  ,  W = $(âˆ‡W[1])"
                    error() 
                end
                =#
                âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
                âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2]   
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[páµ¢] += Î”Î mâ‚€âˆ‡W[1]
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[páµ¢] += Î”Î mâ‚€âˆ‡W[2]
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[pâ±¼] -= Î”Î mâ‚€âˆ‡W[1]
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[pâ±¼] -= Î”Î mâ‚€âˆ‡W[2]
            end
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‚vâˆ‚t_visc!(âˆ‘âˆ‚vâˆ‚t,  âˆ‡W, pairs, m, Ï, câ‚€, Î³, Ïâ‚€) 

Compute laminar shear stresse part of âˆ‚vâˆ‚t. *Add to `âˆ‘âˆ‚vâˆ‚t`.*

```math
\\frac{\\partial \\textbf{v}_i}{\\partial t} = \\sum \\frac{m_j}{\\rho_j}  \\left( 2 \\nu_i \\frac{\\textbf{r}_{ij} \\cdot \\nabla_i W_{ij} }{r_{ij}^2} \\right) \\textbf{v}_{ij}
```
"""
function âˆ‚vâˆ‚t_visc!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, v, Ï, points, pairs, h, mâ‚€, ğœˆ, ptype; minthreads::Int = 1024) 
    Î·Â²    = (0.1 * h) * (0.1 * h)
    gpukernel = @cuda launch=false kernel_âˆ‚vâˆ‚t_visc!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, v, Ï, points, pairs, Î·Â², mâ‚€, ğœˆ, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(minthreads, maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, v, Ï, points, pairs, Î·Â², mâ‚€, ğœˆ, ptype; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚vâˆ‚t_visc!(âˆ‘âˆ‚vâˆ‚t, âˆ‡W, v, Ï, points, pairs, Î·Â², mâ‚€, ğœˆ, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] > 0 && ptype[pâ±¼] > 0
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            rÂ²    = Î”x[1]^2 + Î”x[2]^2 
            Î”v    = (v[páµ¢][1] - v[pâ±¼][1], v[páµ¢][2] - v[pâ±¼][2])
            âˆ‡Wáµ¢â±¼  = âˆ‡W[index]

            ğœˆterm = 4ğœˆ * mâ‚€ * (Î”x[1] * âˆ‡Wáµ¢â±¼[1] + Î”x[2] * âˆ‡Wáµ¢â±¼[2] ) / ((Ïáµ¢ + Ïâ±¼) * (rÂ² + Î·Â²))  

            âˆ‚vâˆ‚t  = (ğœˆterm * Î”v[1], ğœˆterm * Î”v[2])
            âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
            âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2]   
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[páµ¢] +=  âˆ‚vâˆ‚t[1]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[páµ¢] +=  âˆ‚vâˆ‚t[2]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[pâ±¼] -=  âˆ‚vâˆ‚t[1]
            CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[pâ±¼] -=  âˆ‚vâˆ‚t[2]
        end
    end
    return nothing
end
#####################################################################
"""
    
    âˆ‚vâˆ‚t_addgrav!(âˆ‘âˆ‚vâˆ‚t, gvec)  

Add gravity to the momentum equation.
"""
function âˆ‚vâˆ‚t_addgrav!(âˆ‘âˆ‚vâˆ‚t, gvec) 
    gpukernel = @cuda launch=false kernel_âˆ‚vâˆ‚t_addgrav!(âˆ‘âˆ‚vâˆ‚t, gvec) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(âˆ‘âˆ‚vâˆ‚t[1])
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t, gvec; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚vâˆ‚t_addgrav!(âˆ‘âˆ‚vâˆ‚t, gvec) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(âˆ‘âˆ‚vâˆ‚t[1])
        âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
        âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2]
        âˆ‘âˆ‚vâˆ‚tË£[index] -= gvec[1]
        âˆ‘âˆ‚vâˆ‚tÊ¸[index] -= gvec[2]
        
    end
    return nothing
end
#####################################################################
"""
    update_Ïpâˆ‚Ïâˆ‚tÎ”t!(Ï, âˆ‘âˆ‚Ïâˆ‚t, Î”t, Ïâ‚€, ptype) 

Update dencity.

```math
\\rho = \\rho + \\frac{\\partial \\rho}{\\partial t} * \\Delta t
```
"""
function update_Ïpâˆ‚Ïâˆ‚tÎ”t!(Ï, âˆ‘âˆ‚Ïâˆ‚t, Î”t, Ïâ‚€, ptype) 
    if length(Ï) != length(âˆ‘âˆ‚Ïâˆ‚t) error("Wrong length") end
    gpukernel = @cuda launch=false kernel_update_Ï!(Ï, âˆ‘âˆ‚Ïâˆ‚t, Î”t, Ïâ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(Ï)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(Ï, âˆ‘âˆ‚Ïâˆ‚t, Î”t, Ïâ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_update_Ï!(Ï, âˆ‘âˆ‚Ïâˆ‚t, Î”t, Ïâ‚€, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(Ï)
        Ïval = Ï[index] + âˆ‘âˆ‚Ïâˆ‚t[index] * Î”t
        if Ïval < Ïâ‚€ && ptype[index] < 0 Ïval = Ïâ‚€ end
        #=
        if isnan(Ïval) || iszero(Ïval) || Ïval < 0.001
            @cuprintln "kernel update rho: index =  $index, rhoval = $Ïval, rhoi = $(Ï[index]), dpdt = $(âˆ‘âˆ‚Ïâˆ‚t[index]), dt = $Î”t, isboundary = $(isboundary[index])"
            error() 
        end
        =#
        Ï[index] = Ïval
    end
    return nothing
end
#####################################################################
"""
    update_vpâˆ‚vâˆ‚tÎ”t!(v, âˆ‘âˆ‚vâˆ‚t, Î”t, ptype) 

Update vlocity.

```math
\\textbf{v} = \\textbf{v} + \\frac{\\partial \\textbf{v}}{\\partial t} * \\Delta t
```
"""
function update_vpâˆ‚vâˆ‚tÎ”t!(v, âˆ‘âˆ‚vâˆ‚t, Î”t, ptype) 
    if !(length(v) == length(âˆ‘âˆ‚vâˆ‚t[1]) == length(ptype)) error("Wrong length") end
    gpukernel = @cuda launch = false kernel_update_vpâˆ‚vâˆ‚tÎ”t!(v, âˆ‘âˆ‚vâˆ‚t, Î”t, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(v)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx  = cld(Nx, Tx)
    CUDA.@sync gpukernel(v, âˆ‘âˆ‚vâˆ‚t, Î”t, ptype; threads = Tx, blocks = Bx)
end
function kernel_update_vpâˆ‚vâˆ‚tÎ”t!(v, âˆ‘âˆ‚vâˆ‚t, Î”t, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(v) && ptype[index] >= 1
        val = v[index]
        #v[index] = (val[1] + âˆ‘âˆ‚vâˆ‚t[index, 1] * Î”t * ml[index], val[2] + âˆ‘âˆ‚vâˆ‚t[index, 2] * Î”t * ml[index])
        âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
        âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2] 
        v[index] = (val[1] + âˆ‘âˆ‚vâˆ‚tË£[index] * Î”t, val[2] + âˆ‘âˆ‚vâˆ‚tÊ¸[index] * Î”t)
    
        #=
        if isnan(v[index][1] )
            @cuprintln "kernel update v by dvdvt: val = $(val[1]) , dvdt =  $(âˆ‘âˆ‚vâˆ‚t[index, 1] ), dt =  $Î”t"
            error() 
        end
        =#
    end
    return nothing
end
#####################################################################
"""
    update_xpvÎ”t!(x, v, Î”t, ml) 

```math
\\textbf{r} = \\textbf{r} +  \\textbf{v} * \\Delta t
```

"""
function update_xpvÎ”t!(x, v, Î”t) 
    if length(x) != length(v) error("Wrong length") end
    gpukernel = @cuda launch=false kernel_update_xpvÎ”t!(x, v, Î”t) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(x)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(x, v, Î”t; threads = Tx, blocks = Bx)
end
function kernel_update_xpvÎ”t!(x, v, Î”t) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(x)
        xval = x[index]
        vval = v[index]
        x[index] = (xval[1] + vval[1] * Î”t, xval[2] + vval[2] * Î”t)
        #=
        if isnan(x[index][1] )
            @cuprintln "kernel dxdt: xval =  $(xval[1]) , vval =  $(vval[1]),  dt = $Î”t"
            error() 
        end
        =#
    end
    return nothing
end
#####################################################################
"""
    
    symplectic_update!(Ï, ÏÎ”tÂ½, v, vÎ”tÂ½, x, xÎ”tÂ½, âˆ‘âˆ‚Ïâˆ‚t, âˆ‘âˆ‚vâˆ‚t,  Î”t, Ïâ‚€, isboundary, ml) 

Symplectic Position Verlet scheme.

* Parshikov et al, 2000
* Leimkuhler and Matthews, 2016

"""
function symplectic_update!(Ï, ÏÎ”tÂ½, v, vÎ”tÂ½, x, xÎ”tÂ½, âˆ‘âˆ‚Ïâˆ‚t, âˆ‘âˆ‚vâˆ‚t, Î”t, cÎ”x, Ïâ‚€, ptype) 
    if length(x) != length(v) error("Wrong length") end
    gpukernel = @cuda launch=false kernel_symplectic_update!(Ï, ÏÎ”tÂ½, v, vÎ”tÂ½, x, xÎ”tÂ½, âˆ‘âˆ‚Ïâˆ‚t, âˆ‘âˆ‚vâˆ‚t,  Î”t, cÎ”x, Ïâ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(x)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(Ï, ÏÎ”tÂ½, v, vÎ”tÂ½, x, xÎ”tÂ½, âˆ‘âˆ‚Ïâˆ‚t, âˆ‘âˆ‚vâˆ‚t, Î”t, cÎ”x, Ïâ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_symplectic_update!(Ï, ÏÎ”tÂ½, v, vÎ”tÂ½, x, xÎ”tÂ½, âˆ‘âˆ‚Ïâˆ‚t, âˆ‘âˆ‚vâˆ‚t, Î”t, cÎ”x, Ïâ‚€, ptype) # << rename
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(x)

        epsi       = -(âˆ‘âˆ‚Ïâˆ‚t[index] / ÏÎ”tÂ½[index]) * Î”t
        Ïval       = Ï[index]  * (2 - epsi)/(2 + epsi)
        if Ïval < Ïâ‚€ && ptype[index] < 0 Ïval = Ïâ‚€ end

        #=
        if isnan(Ïval) || iszero(Ïval) || Ïval < 0.01
            @cuprintln "kernel update all rho: rhova = $Ïval, epsi = $epsi, drhodt = $(âˆ‘âˆ‚Ïâˆ‚t[index]), rhot12 = $(ÏÎ”tÂ½[index]), dt = $Î”t"
            error() 
        end
        =#
        ÏÎ”tÂ½[index] = Ïval
        Ï[index]    = Ïval
        #=
        if ÏÎ”tÂ½[index] < 0.01
            @cuprintln "kernel update all rho 1: rhova = $Ïval , epsi = $epsi , drhodt = $(âˆ‘âˆ‚Ïâˆ‚t[index]) , rhot12 = $(ÏÎ”tÂ½[index]) $Î”t"
            error() 
        end
        if Ï[index]  < 0.01
            @cuprintln "kernel update all rho 1: rhova = $Ïval , epsi = $epsi , drhodt = $(âˆ‘âˆ‚Ïâˆ‚t[index]) , rhot12 = $(ÏÎ”tÂ½[index]) $Î”t"
            error() 
        end
        =#
        vval        = v[index]
        âˆ‘âˆ‚vâˆ‚tË£      = âˆ‘âˆ‚vâˆ‚t[1]
        âˆ‘âˆ‚vâˆ‚tÊ¸      = âˆ‘âˆ‚vâˆ‚t[2] 
        ml          = ifelse(ptype[index] >= 1, 1.0, 0.0)
        nval        = (vval[1] +  âˆ‘âˆ‚vâˆ‚tË£[index] * Î”t * ml, vval[2]  + âˆ‘âˆ‚vâˆ‚tÊ¸[index] * Î”t * ml)
        vÎ”tÂ½[index] = nval
        v[index]    = nval

        xval           = x[index]
        Î”xË£, Î”xÊ¸       = (vval[1] + nval[1]) * 0.5  * Î”t, (vval[2] + nval[2]) * 0.5  * Î”t
        cÎ”x[1][index] += Î”xË£
        cÎ”x[2][index] += Î”xÊ¸
        xval           = (xval[1] + Î”xË£, xval[2] + Î”xÊ¸)
        xÎ”tÂ½[index]    = xval
        x[index]       = xval
    end
    return nothing
end
#####################################################################
"""    
    Î”t_stepping(buf, a, v, points, câ‚€, h, CFL, timelims) 

"""
function Î”t_stepping(buf, a, v, points, câ‚€, h, CFL, timelims) 

    # some problems can be here if we have cells with big acceleration 
    # may be include only particles that only in simulation range

    Î·Â²  = (0.01)h * (0.01)h

    gpukernel = @cuda launch=false kernel_Î”t_stepping_norm!(buf, a) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(buf)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(buf, a; threads = Tx, blocks = Bx)

    dt1 = sqrt(h / 3maximum(buf)) # mul 1/3

    gpukernel = @cuda launch=false kernel_Î”t_stepping!(buf, v, points, h, Î·Â²) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(buf)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(buf, v, points, h, Î·Â²; threads = Tx, blocks = Bx)
   
    visc  = maximum(buf)
  
    dt2   = h / (câ‚€ + visc)
    dt    = CFL * min(dt1, dt2)
    dt    = min(max(dt, timelims[1]), timelims[2])
    return dt
end
function kernel_Î”t_stepping!(buf, v, points, h, Î·Â²) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(buf)
        vp = v[index]
        pp = points[index]
        buf[index] = abs(h * (vp[1] * pp[1] + vp[2] * pp[2]) / (pp[1]^2 + pp[2]^2 + Î·Â²))
    end
    return nothing
end
function kernel_Î”t_stepping_norm!(buf, a) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(buf)
        buf[index] =  sqrt(a[1][index]^2 + a[2][index]^2) 
    end
    return nothing
end
#####################################################################
#####################################################################
"""
    
    âˆ‚vâˆ‚tpF!(âˆ‘âˆ‚vâˆ‚t, pairs, points, s, H) 

Add surface tension to âˆ‘âˆ‚vâˆ‚t. Modified.

A. Tartakovsky and P. Meakin, Phys. Rev. E 72 (2005)
"""
function âˆ‚vâˆ‚tpF!(âˆ‘âˆ‚vâˆ‚t, pairs, points, s, h, mâ‚€, ptype) 
    gpukernel = @cuda launch=false kernel_âˆ‚vâˆ‚tpF!(âˆ‘âˆ‚vâˆ‚t, pairs, points, s, h, mâ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t, pairs, points, s, h, mâ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_âˆ‚vâˆ‚tpF!(âˆ‘âˆ‚vâˆ‚t, pairs, points, s, h, mâ‚€, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] >= 0 && ptype[pâ±¼] >= 0
           
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            r     = sqrt(Î”x[1]^2 + Î”x[2]^2) 
            if r < 2h
                scos = s * cos(1.5Ï€ * r / 2h)/ (r + (0.1*h))
                âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
                âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2] 
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[páµ¢] +=  scos * Î”x[1] / mâ‚€
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[páµ¢] +=  scos * Î”x[2] / mâ‚€
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[pâ±¼] -=  scos * Î”x[1] / mâ‚€
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[pâ±¼] -=  scos * Î”x[2] / mâ‚€
            end

        end
    end
    return nothing
end
###################################################################################
# Dynamic Particle Collision (DPC) 
# https://arxiv.org/pdf/2110.10076.pdf
# Stability and accuracy of the weakly compressible SPH with par-
# ticle regularization techniques
# Mojtaba Jandaghian, Herman Musumari Siaben, Ahmad Shakibaeinia
###################################################################################
"""
    
    dpcreg!(âˆ‘Î”vdpc, v, Ï, P, pairs, points, sphkernel, lâ‚€, Pmin, Pmax, Î”t, Î», dpckernlim) 

Dynamic Particle Collision (DPC) correction. *Replace all values and update `âˆ‘Î”vdpc`.*


```math
\\delta \\textbf{v}_i^{DPC} = \\sum k_{ij}\\frac{m_j}{m_i + m_j}v_{ij}^{coll} + \\frac{\\Delta  t}{\\rho_i}\\sum \\phi_{ij} \\frac{2V_j}{V_i + V_j}\\frac{p_{ij}^b}{r_{ij}^2 + \\eta^2}\\textbf{r}_{ij}

\\\\

(v_{ij}^{coll} , \\quad \\phi_{ij}) = \\begin{cases} (\\frac{\\textbf{v}_{ij}\\cdot \\textbf{r}_{ij}}{r_{ij}^2 + \\eta^2}\\textbf{r}_{ji}, \\quad 0) & \\textbf{v}_{ij}\\cdot \\textbf{r}_{ij} < 0 \\\\ (0, \\quad 1) &  otherwise \\end{cases}

\\\\
p_{ij}^b = \\tilde{p}_{ij} \\chi_{ij} 

\\\\

\\tilde{p}_{ij} = max(min(\\lambda |p_i + p_j|, \\lambda p_{max}), p_{min})

\\\\

\\chi_{ij}  = \\sqrt{\\frac{\\omega({r}_{ij}, l_0)}{\\omega(l_0/2, l_0)}}

\\\\

k_{ij} =  \\begin{cases} \\chi_{ij} & 0.5 \\le {r}_{ij}/l_0 < 1 \\\\ 1 & {r}_{ij}/l_0 < 0.5 \\end{cases}

```

Mojtaba Jandaghian, Herman Musumari Siaben, Ahmad Shakibaeinia, Stability and accuracy of the weakly compressible SPH with particle regularization techniques https://arxiv.org/pdf/2110.10076.pdf

"""
function dpcreg!(âˆ‘Î”vdpc, v, Ï::CuArray{T}, P::CuArray{T}, pairs, points, sphkernel, lâ‚€, Pmin, Pmax, Î”t, Î», dpckernlim) where T
    fill!(âˆ‘Î”vdpc[1], zero(T))
    fill!(âˆ‘Î”vdpc[2], zero(T))
    lâ‚€â»Â¹     = 1 / lâ‚€  
    whâ»Â¹     = 1 / ğ’²(sphkernel, 0.5, lâ‚€â»Â¹)
    gpukernel = @cuda launch=false kernel_dpcreg!(âˆ‘Î”vdpc, v, Ï, P, pairs, points, sphkernel, whâ»Â¹, lâ‚€, lâ‚€â»Â¹, Pmin, Pmax, Î”t, Î», dpckernlim) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘Î”vdpc, v, Ï, P, pairs, points, sphkernel, whâ»Â¹, lâ‚€, lâ‚€â»Â¹, Pmin, Pmax, Î”t, Î», dpckernlim; threads = Tx, blocks = Bx)
end
function kernel_dpcreg!(âˆ‘Î”vdpc, v, Ï, P, pairs, points, sphkernel, whâ»Â¹, lâ‚€, lâ‚€â»Â¹, Pmin, Pmax, Î”t, Î», dpckernlim) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x

    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            Î·Â²    = (0.1 * lâ‚€) * (0.1 * lâ‚€)
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]

            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            Î”v    = (v[páµ¢][1] - v[pâ±¼][1], v[páµ¢][2] - v[pâ±¼][2])
            rÂ²    = Î”x[1]^2 + Î”x[2]^2 
            r     = sqrt(rÂ²) 
            u     = r * lâ‚€â»Â¹
            w     = ğ’²(sphkernel, u, lâ‚€â»Â¹)

            Ï‡     = sqrt(w * whâ»Â¹)

            k     = ifelse(u < dpckernlim, 1.0, Ï‡)

            Páµ‡    = Ï‡ * max(min(Î» * abs(P[páµ¢] + P[pâ±¼]), Î» * Pmax), Pmin)

            vr   = Î”v[1] * Î”x[1] +  Î”v[2] * Î”x[2] 

            if vr < 0
                # Î”vdpc = âˆ‘ k * 2mâ±¼ / (máµ¢ + mâ±¼) * vá¶œ   | mâ±¼ = máµ¢ |  => Î”vdpc = âˆ‘ k * vá¶œ
                vrdr    = vr / (rÂ² + Î·Â²)
                vá¶œ      = (-vrdr * Î”x[1],  -vrdr * Î”x[2])
                Î”vdpc   = (k * vá¶œ[1],  k * vá¶œ[2])
            else
                # Î”vdpc = Î”t / Ïáµ¢ * âˆ‘ 2Váµ¢ / (Váµ¢ + Vâ±¼) * Páµ‡ / (rÂ² + Î·Â²) * Î”x
                # V = m / Ï
                # Î”vdpc = Î”t * âˆ‘ 2 / (Ïáµ¢ + Ïâ±¼) * Páµ‡ / (rÂ² + Î·Â²) * Î”x
                tvar = 2Î”t* Páµ‡ / ((Ïáµ¢ + Ïâ±¼) * (rÂ² + Î·Â²))
                Î”vdpc = (tvar * Î”x[1], tvar * Î”x[2])
            end
            
            âˆ‘Î”vdpcË£ = âˆ‘Î”vdpc[1]
            âˆ‘Î”vdpcÊ¸ = âˆ‘Î”vdpc[2]   
            CUDA.@atomic âˆ‘Î”vdpcË£[páµ¢] +=  Î”vdpc[1]
            CUDA.@atomic âˆ‘Î”vdpcÊ¸[páµ¢] +=  Î”vdpc[2]
            CUDA.@atomic âˆ‘Î”vdpcË£[pâ±¼] -=  Î”vdpc[1]
            CUDA.@atomic âˆ‘Î”vdpcÊ¸[pâ±¼] -=  Î”vdpc[2]
        end
    end
    return nothing
end

"""
    update_dpcreg!(v, x, âˆ‘Î”vdpc, Î”t, ptype) 

Update velocity and position.
"""
function update_dpcreg!(v, x, âˆ‘Î”vdpc, Î”t, ptype) 
    if length(x) != length(v) error("Wrong length") end
    gpukernel = @cuda launch=false kernel_update_dpcreg!(v, x, âˆ‘Î”vdpc, Î”t, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(x)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(v, x, âˆ‘Î”vdpc, Î”t, ptype; threads = Tx, blocks = Bx)
end
function kernel_update_dpcreg!(v, x, âˆ‘Î”vdpc, Î”t, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(x)
        if ptype[index] >= 1
            xval = x[index]
            vval = v[index]
            dpcval = (âˆ‘Î”vdpc[1][index], âˆ‘Î”vdpc[2][index])

            v[index] = (vval[1] + dpcval[1], vval[2] + dpcval[2])
            x[index] = (xval[1] + dpcval[1] * Î”t, xval[2] + dpcval[2] * Î”t)
        end
    end
    return nothing
end
###################################################################################
# Corrected Smoothed Particle Method (CSPM)
# Chen, J. K., Beraun, J. E., & Carney, T. C. (1999). 
# A corrective smoothed particle method for boundary value problems in heat conduction. International Journal for Numerical Methods in Engineering, 
# 46(2), 231â€“252. doi:10.1002/(sici)1097-0207(19990920)46:2<231::aid-nme672>3.0.co;2-k
# https://upcommons.upc.edu/bitstream/handle/2117/187607/Particles_2017-82_A%20SPH%20model%20for%20prediction.pdf
# A SPH MODEL FOR PREDICTION OF OIL SLICK DIAMETER IN
# THE GRAVITY-INERTIAL SPREADING PHASE
# Carlos Alberto Dutra Fraga Filho, Reflective Boundary Conditions Coupled With the SPH Method for 
# the Three-Dimensional Simulation of Fluid-Structure Interaction With Solid Boundaries
###################################################################################
"""
    
    cspmcorr!(âˆ‘Ïcspm1, âˆ‘Ïcspm2, Ï, mâ‚€, pairs, points, sphkernel, Hâ»Â¹)

Corrected Smoothed Particle Method (CSPM) Density Renormalisation.

```math

\\rho_{i}^{norm} = \\frac{\\sum m_j W}{\\sum \\frac{m_j}{\\rho_j} W}
```

Chen JK, Beraun JE, Carney TC (1999) A corrective smoothed particle method for boundary value problems in heat conduction. Int. J. Num. Meth. Engng. https://doi.org/10.1002/(SICI)1097-0207(19990920)46:2<231::AID-NME672>3.0.CO;2-K
"""
function cspmcorr!(âˆ‘Ïcspm, W, Ï::CuArray{T}, mâ‚€, pairs, ptype) where T
    fill!(âˆ‘Ïcspm[1], zero(T))
    fill!(âˆ‘Ïcspm[2], zero(T))

    gpukernel = @cuda launch=false kernel_cspmcorr_1!(âˆ‘Ïcspm, W, Ï, mâ‚€, pairs, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘Ïcspm, W, Ï, mâ‚€, pairs, ptype; threads = Tx, blocks = Bx)

    gpukernel2 = @cuda launch=false kernel_cspmcorr_2!(Ï, âˆ‘Ïcspm) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(Ï)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel2(Ï, âˆ‘Ïcspm; threads = Tx, blocks = Bx)
end
function kernel_cspmcorr_1!(âˆ‘Ïcspm, W, Ï, mâ‚€, pairs, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x

    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] >= 0 && ptype[pâ±¼] >= 0
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]
            w     = W[index]
            CUDA.@atomic âˆ‘Ïcspm[1][páµ¢] +=  mâ‚€ * w
            CUDA.@atomic âˆ‘Ïcspm[2][páµ¢] +=  w * mâ‚€ / Ïâ±¼

            CUDA.@atomic âˆ‘Ïcspm[1][pâ±¼] +=  mâ‚€ * w
            CUDA.@atomic âˆ‘Ïcspm[2][pâ±¼] +=  w * mâ‚€ / Ïáµ¢
        end
    end
    return nothing
end
function kernel_cspmcorr_2!(Ï, âˆ‘Ïcspm) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(Ï) 
        newÏ = âˆ‘Ïcspm[1][index] / âˆ‘Ïcspm[2][index]
        if !isnan(newÏ) Ï[index] = newÏ end
    end
    return nothing
end
#####################################################################
# XSPH Correction 
#####################################################################
"""
    
    xsphcorr!(âˆ‘Î”vxsph, v, Ï, W, pairs, mâ‚€)

The XSPH correction.

```math

\\hat{\\textbf{v}_{i}} = - \\epsilon \\sum m_j \\frac{\\textbf{v}_{ij}}{\\overline{\\rho}_{ij}} W_{ij}

```

* Monaghan JJ (1989) On the problem of penetration in particle methods. J Comput Phys. https://doi.org/10.1016/0021-9991(89)90032-6

* Carlos Alberto Dutra Fraga Filho, Reflective Boundary Conditions Coupled With the SPH Method for the Three-Dimensional Simulation of Fluid-Structure Interaction With Solid Boundaries
"""
function xsphcorr!(âˆ‘Î”vxsph, pairs, W, Ï, v, mâ‚€, ğœ€)
    fill!(âˆ‘Î”vxsph[1], zero(T))
    fill!(âˆ‘Î”vxsph[2], zero(T))
    gpukernel = @cuda launch=false kernel_xsphcorr!(âˆ‘Î”vxsph, pairs, W, Ï, v, mâ‚€, ğœ€) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘Î”vxsph, pairs, W, Ï, v, mâ‚€, ğœ€; threads = Tx, blocks = Bx)
end
function kernel_xsphcorr!(âˆ‘Î”vxsph, pairs, W, Ï, v, mâ‚€, ğœ€) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0
            Î”v    = (v[páµ¢][1] - v[pâ±¼][1], v[páµ¢][2] - v[pâ±¼][2])
            Ïáµ¢    = Ï[páµ¢]
            Ïâ±¼    = Ï[pâ±¼]
            xsph  = 2mâ‚€ * ğœ€ * W[index] / (Ïáµ¢ + Ïâ±¼)
            xsphv = (xsph * Î”v[1], xsph * Î”v[2])
            âˆ‘Î”vxsphË£ = âˆ‘Î”vxsph[1]
            âˆ‘Î”vxsphÊ¸ = âˆ‘Î”vxsph[2]
            CUDA.@atomic âˆ‘Î”vxsphË£[páµ¢] -=  xsphv[1]
            CUDA.@atomic âˆ‘Î”vxsphÊ¸[páµ¢] -=  xsphv[2]
            CUDA.@atomic âˆ‘Î”vxsphË£[pâ±¼] +=  xsphv[1]
            CUDA.@atomic âˆ‘Î”vxsphÊ¸[pâ±¼] +=  xsphv[2]
        end
    end
    return nothing
end
"""
    update_xsphcorr!(v, âˆ‘Î”vxsph, ptype) 

Update velocity.
"""
function update_xsphcorr!(v, âˆ‘Î”vxsph, ptype) 
    gpukernel = @cuda launch=false kernel_update_dpcreg!(v, âˆ‘Î”vxsph, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(x)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(v, âˆ‘Î”vxsph, ptype; threads = Tx, blocks = Bx)
end
function kernel_update_xsphcorr!(v, âˆ‘Î”vxsph, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x
    if index <= length(x)
        if ptype[index] > 0
            vval = v[index]
            xsph = âˆ‘Î”vxsph[index]
            v[index] = (vval[1] + xsph[1], vval[2] + xsph[2])
        end
    end
    return nothing
end
#####################################################################
# * Rapaport D.C., 2004. The art of molecular dynamics simulation.
#
# Carlos Alberto Dutra Fraga Filho Julio TomÃ¡s Aquije Chacaltana
# BOUNDARY TREATMENT TECHNIQUES IN SMOOTHED
# PARTICLE HYDRODYNAMICS: IMPLEMENTATIONS IN FLUID
# AND THERMAL SCIENCES AND RESULTS ANALYSIS
#####################################################################
"""
    fbmolforce!(âˆ‘âˆ‚vâˆ‚t, pairs, points, d, râ‚€, ptype)

The repulsive force exerted by the virtual particle on the fluid particle.


```math
F = D * \\frac{\\left( (\\frac{r_0}{\\textbf{r}_{ij}})^{n_1} - (\\frac{r_0}{\\textbf{r}_{ij}})^{n_2}\\right)}{r_{ij}^2}
```
* Rapaport, 2004

nâ‚ = 12

nâ‚‚ = 4
"""
function fbmolforce!(âˆ‘âˆ‚vâˆ‚t, pairs, points, d, râ‚€, ptype)
    gpukernel = @cuda launch=false kernel_fbmolforce!(âˆ‘âˆ‚vâˆ‚t, pairs, points, d, râ‚€, ptype) 
    config = launch_configuration(gpukernel.fun)
    Nx = length(pairs)
    maxThreads = config.threads
    Tx  = min(maxThreads, Nx)
    Bx = cld(Nx, Tx)
    CUDA.@sync gpukernel(âˆ‘âˆ‚vâˆ‚t, pairs, points, d, râ‚€, ptype; threads = Tx, blocks = Bx)
end
function kernel_fbmolforce!(âˆ‘âˆ‚vâˆ‚t, pairs, points, d, râ‚€, ptype) 
    index = (blockIdx().x - Int32(1)) * blockDim().x + threadIdx().x

    if index <= length(pairs)
        pair  = pairs[index]
        páµ¢    = pair[1]; pâ±¼ = pair[2]
        if páµ¢ != 0 && ptype[páµ¢] * ptype[pâ±¼] < 0
            xáµ¢    = points[páµ¢]
            xâ±¼    = points[pâ±¼]
            Î”x    = (xáµ¢[1] - xâ±¼[1], xáµ¢[2] - xâ±¼[2])
            rÂ²    = Î”x[1]^2 + Î”x[2]^2 
            r     = sqrt(Î”x[1]^2 + Î”x[2]^2)
            if r < râ‚€
                Fc    = d * ((râ‚€ / r)^12 - (râ‚€ / r)^4) / rÂ² 
                F     = (Î”x[1] * Fc, Î”x[2] * Fc)
                
                âˆ‘âˆ‚vâˆ‚tË£ = âˆ‘âˆ‚vâˆ‚t[1]
                âˆ‘âˆ‚vâˆ‚tÊ¸ = âˆ‘âˆ‚vâˆ‚t[2] 

                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[páµ¢] +=  F[1]
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[páµ¢] +=  F[2]
                
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tË£[pâ±¼] -=  F[1]
                CUDA.@atomic âˆ‘âˆ‚vâˆ‚tÊ¸[pâ±¼] -=  F[2]
            end
        end
    end
    return nothing
end